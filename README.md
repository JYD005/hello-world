# Logistic Regression from the scratch in Python
logistic regression tends to find the weights that maximize the likelihood of producing a given data and using it to categorize the new data.
Gradient ascent is employed to solve the optimization problem. Gradient ascent is similar to gradient descent, the former maximizes while the latter minimizes a function.

THE STEPS TAKEN ARE AS FOLLOWS:
- Choosing a link function: sigmoid
- Maximizing the Likelihood: log-likelihood
- Calculating the gradient
- Building the Logistic Regression Function: logistic_regression
- Run the model
- Comparing accuracy of the model with sklearn LogisticRegression
